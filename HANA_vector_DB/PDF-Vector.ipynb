{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install generative-ai-hub-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633178a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hana-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "import os\n",
    "\n",
    "os.environ[\"AICORE_AUTH_URL\"] = \"AI_CORE_URL\"\n",
    "os.environ[\"AICORE_CLIENT_ID\"] = 'CLIENT_ID'\n",
    "os.environ[\"AICORE_CLIENT_SECRET\"] = 'SECRET'\n",
    "os.environ[\"AICORE_RESOURCE_GROUP\"] = 'USER_GROUP (USUAL IS DEFAULT)'\n",
    "os.environ[\"AICORE_BASE_URL\"] = \"URL\"\n",
    "\n",
    "\n",
    "proxy_client = get_proxy_client('gen-ai-hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c43a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import ConnectionContext\n",
    "#cc = Connectioncontext(userkey='VDB_beta' encript=true)\n",
    "\n",
    "cc = ConnectionContext(\n",
    "    address='*********.hanacloud.ondemand.com',\n",
    "    port=443, \n",
    "    user='DBUSER', \n",
    "    password='DBPASS', \n",
    "    encrypt=True\n",
    ")\n",
    "\n",
    "#print(cc.hana.version())\n",
    "print(cc.get_current_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b53d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hdbcli\n",
    "from hdbcli import dbapi\n",
    "\n",
    "conn = dbapi.connect(\n",
    "    address='*********.hanacloud.ondemand.com',\n",
    "    port=443, \n",
    "    user='DBUSER', \n",
    "    password='DBPASS', \n",
    "    encrypt=True\n",
    ")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0968e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA #ok\n",
    "from langchain.prompts import PromptTemplate #ok\n",
    "\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "     PyPDFLoader(\"PATH_TOPDF.pdf\")]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "    \n",
    "pdfdata=loader.load()\n",
    "document = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=100)\n",
    "text_chunks = text_splitter.split_documents(docs)\n",
    "text_chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_embedding_model \n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "embeddings = init_embedding_model('text-embedding-ada-002')\n",
    "db = HanaDB(embedding=embeddings, connection=conn, table_name=\"PDF\")\n",
    "db.delete(filter={})\n",
    "db.add_documents(text_chunks)\n",
    "print(text_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1b4ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "def get_embedding(input, model=\"text-embedding-ada-002\") -> str: \n",
    "    response = embeddings.create(\n",
    "    model_name = model,\n",
    "    input=input\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Setting page title and header\n",
    "st.set_page_config(page_title=\"FAQ chatbot\", page_icon=\":speech-balloon:\", initial_sidebar_state=\"collapsed\")\n",
    "st.title(\"FAQ chatbot\")\n",
    "\n",
    "# Sidebar\n",
    "st.sidebar.title(\"Administration\")\n",
    "restart_button = st.sidebar.button(\"Start again\", key=\"restart\")\n",
    "\n",
    "#Performing the cosine similarity search by pass the query vector.\n",
    "\n",
    "import requests\n",
    "import json \n",
    "\n",
    "def run_vector_search(query: str, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    if metric == 'L2DISTANCE': \n",
    "        sort = 'ASC'\n",
    "    else: \n",
    "        sort ='DESC'\n",
    "    query_vector = get_embedding(query)\n",
    "    sql = '''SELECT TOP 2 \"VEC_TEXT\" FROM \"DBADMIN\".\"PDF\"\n",
    "    ORDER BY \"COSINE_SIMILARITY\"(\"VEC_VECTOR\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=4,metric=\"COSINE_SIMILARITY\",qv=query_vector,sort=sort)\n",
    "    hdf = cc.sql(sql)\n",
    "    df_context = hdf.head(k).collect()\n",
    "    return df_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc65d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VEC_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. Enter the name and version (if applicable) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. In the ML Ops  app, choose Scenarios  and c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            VEC_TEXT\n",
       "0  5. Enter the name and version (if applicable) ...\n",
       "1  2. In the ML Ops  app, choose Scenarios  and c..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what models can I use?\"\n",
    "df_context = run_vector_search(query=query,metric=\"COSINE_SIMILARITY\",k=4)\n",
    "df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583bf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
